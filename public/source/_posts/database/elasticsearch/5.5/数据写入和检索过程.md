---
title: Elasticsearch5.5 数据写入和检索过程
categories: elasticsearch
tags:
  - elasticsearch
keywords: elasticsearch
abbrlink: 731472ea
date: 2022-02-15 12:45:00
---


## 数据写入

### Shard：分片

对于海量数据的存储检索聚合等操作，ES使用分片来处理，每个索引在创建的时候可以指定分片的数量以及分片对应的副本分片数量。这样每个分片都会有一个主分片和多个副本分片。

在进行写入操作的时候，根据参数`_routing`(如果么有提供该参数，默认使用`_id`)，利用公式：hash(routing)%num_primary_shards，计算出应该存入到哪个分片中，然后在集群节点中找到该分片进行相关操作。

### Refresh：数据何时能被检索？

当ES写入数据后，首选数据会被存储在buffer缓存中，这个时候该条数据是不能被检索到的。`refresh`操作会将buffer缓存中数据生成为一个新的Segment（同时还需要写translog），这时候我们添加的数据可以被检索到。（在创建索引的时候可以指定参数`index.refresh_interval`该参数为`refresh`操作间隔的时长，默认1s）



API的使用：

> refresh间隔时长，也可以在请求中指定；或者调用refresh API来执行
>
> ```properties
> # 刷新所有的索引
> POST /_refresh 
> # 刷新blogs索引
> POST /blogs/_refresh 
> ```
>
> ```properties
> # 每30秒刷新 my_logs 索引。
> PUT /my_logs
> {
>   "settings": {
>     "refresh_interval": "30s" 
>   }
> }
> ```
>
> ```properties
> # 关闭索引刷新，（如果你在大批量的导入数据可以先关闭，然后在打开）
> PUT /my_logs/_settings
> { "refresh_interval": -1 } 
> ```
>
> ```properties
> # 添加文档后，强制刷新
> PUT my_blog/_doc/1?refresh=true
> {
> 	xxxxx
> }
> ```
>
> 或者：
>
> ```properties
> curl -XPOST 'localhost:9200/my_index/_refresh'
> ```
>
> 



### Flush：数据存储

经过refresh操作，插入的数据可以被检索到，此时的数据还在内存中，如果服务器宕机数据就会丢失，为了保证数据的有效持久化，ES提供了`flush`操作。

在执行flush操作之前，为了解决内存中的数据由于外部原因会丢失的问题，引入了translog。ES底层还是使用了Lucene，当ES插入文档时候，先生成 Lucene索引，同时还会将数据追加写入到translog中（持久化到硬盘上，可以同步也可以异步），如果发生宕机等重启后可以从这个文件中恢复内存中的数据。

当这个translog大小达到一定的阈值或者根据定时器配置的周期（参数：**index.translog.flush_threshold_size**，**index.translog.sync_interval**），就会执行一次flush操作：

1. 将buffer中的数据全部生成segment
2. 将内存中所有的segment强制存储到硬盘上，记录 commit point
3. translog 存储到拼盘上



### Merge：调度任务

在不断的refresh后，内存中会有很多的Segment，ES提供独立的线程去完成这些小的Segment的合并工作。通过参数**index.merge.scheduler.max_thread_count**，动态配置最大线程数。

### 数据写入流程

如下图所示：

![](https://blog.lichenghao.cn/upload/2022/07/068982c8602b.png)























