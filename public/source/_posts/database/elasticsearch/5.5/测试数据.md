---
title: Elasticsearch 测试数据
categories: elasticsearch
tags:
  - elasticsearch
keywords: elasticsearch
abbrlink: 9864bbd5
date: 2022-02-15 12:30:00
---
## 导入官方的测试数据

数据地址：https://github.com/elastic/elasticsearch/blob/master/docs/src/test/resources/accounts.json

或者：https://wws.lanzous.com/i0ptsjzxi2h

kibana 创建索引：

```json
PUT /bank
{
  "settings": {
    "number_of_shards": 5,
    "number_of_replicas": 1
  },
  "mappings": {
    "account":{
      "properties": {
        "account_number":{
          "type": "integer"
        },
        "balance":{
          "type": "double"
        },
        "firstname":{
          "type": "keyword"
        },
        "lastname":{
          "type": "keyword"
        },
        "age":{
          "type": "integer"
        },
        "gender":{
          "type": "byte"
        },
        "address":{
          "type": "text"
        },
        "employer":{
          "type": "keyword"
        },
        "email":{
          "type": "text"
        },
        "city":{
          "type": "keyword"
        },
        "state":{
          "type": "keyword"
        }
      }
    }
  }
}
```

使用 postman

`post请求：localhost:9200/bank/account/_bulk?pretty&refresh `

参数选择 binary,选择上面下载的文件 accounts.json

![](https://blog.lichenghao.cn/upload/2022/07/97c129351a7eed058d4f8e831ac5dc54.png)

官方的测试数据都是英文的数据，我们可能需要一些中文的测试数据，导入网友整理的商品数据

测试数据文件：https://wws.lanzous.com/iV61xkta1hc

kibana 创建创建索引：（这里面如果没有 IK 分词器，可以安装或者去掉 analyzer 和 search_analyzer，使用系统默认的分词器）

```json
PUT /pditems
{
    "settings": {
        "index.analysis.analyzer.default.type": "ik_max_word",
        "number_of_shards": 3,
        "number_of_replicas": 2
    },
    "mappings": {
        "item": {
            "properties": {
                "id": {
                    "type": "long"
                },
                "brand": {
                    "type": "text",
                    "analyzer": "ik_smart"
                },
                "title": {
                    "type": "text",
                    "analyzer": "ik_max_word",
                    "search_analyzer": "ik_smart"
                },
                "sell_point": {
                    "type": "text",
                    "analyzer": "ik_max_word",
                    "search_analyzer": "ik_smart"
                },
                "price": {
                    "type": "float"
                },
                "barcode": {
                    "type": "keyword"
                },
                "image": {
                    "type": "keyword"
                },
                "cid": {
                    "type": "long"
                },
                "status": {
                    "type": "byte"
                },
                "created": {
                    "type": "date",
                    "format": "yyyy-MM-dd HH:mm:ss"
                },
                "updated": {
                    "type": "date",
                    "format": "yyyy-MM-dd HH:mm:ss"
                }
            }
        }
    }
}
```

然后 postman 指定文章类型为 item 执行即可

`http://localhost:9200/pditems/item/_bulk?pretty&refresh`

![](https://blog.lichenghao.cn/upload/2022/07/e444d1c7gy1gn2bhij0v6j20tr0cndg3.jpg)





## 自定义数据插入

利用API插入，测试用插入几十万，几百万也很快。

```java
/**
 * 批量添加数据
 */
public class AddAlarms {

    public static void main(String[] args) throws Exception {
        // 多线程下慎用哦
        DateFormat df = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.000XXX");
        TransportClient client = null;
        try {
            Settings settings = Settings.builder()
                    .put("cluster.name", "elasticsearch")
                    .put("client.transport.sniff", true)
                    // 使用认证的话，下面使用PreBuiltXPackTransportClient
                    .put("xpack.security.user", "elastic:changeme")
                    .build();
            // 没用XPack  client = new PreBuiltTransportClient(settings);
            client = new PreBuiltXPackTransportClient(settings);
            InetSocketTransportAddress transportAddresses = new
                    InetSocketTransportAddress(InetAddress.getByName("192.168.100.100"), 9300);
            client.addTransportAddresses(transportAddresses);

            BulkRequestBuilder prepareBulk = null;
            // 天数 模拟每天插入一万条数据
            for (int i = 1; i <= 5; i++) {
                System.out.println("第" + i + "天");
                prepareBulk = client.prepareBulk();
                String date = df.format(DateUtils.addDays(new Date(), -15 - i));
                System.out.println(date);
                // 每天多少条
                for (int j = 1; j <= 10000; j++) {
                    String alarmId = UUID.randomUUID().toString();
                    IndexRequestBuilder prepareIndex = client.prepareIndex("soc_alarm_info", "base", alarmId);
                    XContentBuilder obj = XContentFactory.jsonBuilder()
                            .startObject()
                            .field("create_time", date)
                        	// 其他的字段 ....
                            .endObject();
                    prepareIndex.setSource(obj);
                    prepareBulk.add(prepareIndex);
					
                    // 5,5版本可以可以设置多个type,为父子关系。以后的版本给去掉了
                    // String eventId = UUID.randomUUID().toString();
                    // IndexRequestBuilder prepareIndex1 = client.prepareIndex("soc_alarm_info", "event", eventId);
                    // prepareIndex1.setRouting(alarmId).setParent(alarmId);
                    // XContentBuilder obj1 = XContentFactory.jsonBuilder()
                    //         .startObject()
                    //         .field("ip", "192.168.20.30")
                    //         .endObject();
                    // prepareIndex1.setSource(obj1);
                    // prepareBulk.add(prepareIndex1);

                    // 每1万条提交1次
                    if (j % 10000 == 0) {
                        BulkResponse bulkResponse = prepareBulk.get();
                        System.out.println(bulkResponse.getTook());
                    }
                }
                if (prepareBulk.numberOfActions() > 0) {
                    BulkResponse bulkResponse = prepareBulk.get();
                    System.out.println(bulkResponse.getTook());
                }
            }
        } finally {
            if (client != null) {
                client.close();
            }
        }
    }
}
```

主要依赖：

```xml
<!--spring-data-elasticsearch -->
<dependency>
    <groupId>org.springframework.data</groupId>
    <artifactId>spring-data-elasticsearch</artifactId>
    <!--
    <exclusions>
        <exclusion>
            <artifactId>jackson-core</artifactId>
            <groupId>com.fasterxml.jackson.core</groupId>
        </exclusion>
        <exclusion>
            <artifactId>spring-tx</artifactId>
            <groupId>org.springframework</groupId>
        </exclusion>
        <exclusion>
            <artifactId>spring-core</artifactId>
            <groupId>org.springframework</groupId>
        </exclusion>
    </exclusions>
    --> 
</dependency>
 <dependency>
     <groupId>org.elasticsearch.client</groupId>
     <artifactId>x-pack-transport</artifactId>
     <version>5.5.0</version>
</dependency>
```



